{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Stores and Retrievers\n",
    "\n",
    "This tutorial will cover LangChain's vector store and retriever abstractions. These abstractions are designed to support retrieval of data from vector databases and other soures for integration with LLM workflows. They are important for applications that fetch data to be reasoned over as part of model inference, as in the case of Retrieval-Augmented Generation (RAG).\n",
    "\n",
    "### Concepts\n",
    "\n",
    "This guide focuses on retrieval of text data. We will cover the following concepts:\n",
    "\n",
    "- Documents;\n",
    "- Vector Stores;\n",
    "- Retrievers.\n",
    "\n",
    "### Setup\n",
    "\n",
    "We're expected to be working in a jupyter notebook. We also need the `langchain`, `langchain-chroma`, and `langchain-openai` packages (oh joy):\n",
    "\n",
    "```ps\n",
    "conda install langchain langchain-chroma langchain-openai -c conda-forge\n",
    "```\n",
    "\n",
    "We already have `langchain`, `langchain-chroma` will not install from conda-forge. I'm not sure that we'll be using the `langchain-openai` package, so we'll hold off on installing it until we know we need it. I'll pip `langchain-chroma` for now.\n",
    "\n",
    "```ps\n",
    "pip install langchain-chroma\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents\n",
    "\n",
    "LangChain implements a [Document](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html) abstraction, which is intended to represent a unit of text and associated metadata. It has two attributes:\n",
    "\n",
    "- `page_content`: a string representing the content;\n",
    "- `metadata`: a dictionary containing arbitrary metadata.\n",
    "\n",
    "The `metadata` attribute can capture information about the source of the document, its relationship to other documents, and other information. Note that an individual `Document` object often represents a chunk of a larger document.\n",
    "\n",
    "Let's generate some sample documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Goldfish are popular pets for beginners, requiring relatively simple care.\",\n",
    "        metadata={\"source\": \"fish-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Parrots are intelligent birds capable of mimicking human speech.\",\n",
    "        metadata={\"source\": \"bird-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Rabbits are social animals that need plenty of space to hop around.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five documents, three sources.\n",
    "\n",
    "## Vector Stores\n",
    "\n",
    "Vector search is a common way to store and search over unstructured data (such as unstructured text). The idea is to store numeric vectors that are associated with the text. Given a query, we can [embed](https://python.langchain.com/v0.2/docs/concepts/#embedding-models) it as a vector of the same dimension and use vector similarity metrics to identify related data in the store.\n",
    "\n",
    "LangChain [VectorStore](https://api.python.langchain.com/en/latest/vectorstores/langchain_core.vectorstores.VectorStore.html) objects contain methods for adding text and `Document` objects to the store, and querying them using various similarity metrics. They are often initialized with [embedding](https://python.langchain.com/v0.2/docs/how_to/embed_text/) models, which determine how text data is translated to numeric vectors.\n",
    "\n",
    "LangChain includes a suite of [integrations](https://python.langchain.com/v0.2/docs/integrations/vectorstores/) with different vector store technologies. Some vector stores are hosted by a provider (e.g., various cloud providers) and require specific credentials to use; some (such as [Postgres](https://python.langchain.com/v0.2/docs/integrations/vectorstores/pgvector/)) run in separate infrastructure that can be run locally or via a third-party; others can run in-memory for lightweight workloads. Here we will demonstrate usage of LangChain VectorStores using [Chroma](https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/), which includes an in-memory implementation.\n",
    "\n",
    "To instantiate a vector store, we often need to provide an [embedding](https://python.langchain.com/v0.2/docs/how_to/embed_text/) model to specify how text should be converted to a numeric vector. Here we will deviate from the tutorial a bit. They use the [OpenAI embeddings](https://python.langchain.com/v0.2/docs/integrations/text_embedding/openai/). We're going to be switching from even what we were doing yesterday and using Mistralv0.3, as it natively supports function calling. We can use `OllamaEmbeddings` to ask the model for the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding=OllamaEmbeddings(\n",
    "        model=\"mistral:v0.3\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling .from_documents here will add the documents to the vector store. [VectorStore](https://api.python.langchain.com/en/latest/vectorstores/langchain_core.vectorstores.VectorStore.html) implements methods for adding documents that can also be called after the object is instantiated. Most implementations will allow you to connect to an existing vector store--e.g., by providing a client, index name, or other information. See the documentation for a specific [integration](https://python.langchain.com/v0.2/docs/integrations/vectorstores/) for more detail.\n",
    "\n",
    "Once we've instantiated a `VectorStore` that contains documents we can query it. `VectorStore` includes methods for querying:\n",
    "\n",
    "- Synchronously and asynchronously;\n",
    "- By string query and by vector;\n",
    "- With and without returning similarity scores;\n",
    "- By similarity and [maximum marginal relevance](https://api.python.langchain.com/en/latest/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.max_marginal_relevance_search).\n",
    "\n",
    "The methods will generally include a lost of [Document](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) objects in their outputs.\n",
    "\n",
    "### Examples\n",
    "\n",
    "Return documents based on similarity to a string query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Cats are independent pets that often enjoy their own space.', metadata={'source': 'mammal-pets-doc'}),\n",
       " Document(page_content='Cats are independent pets that often enjoy their own space.', metadata={'source': 'mammal-pets-doc'}),\n",
       " Document(page_content='Dogs are great companions, known for their loyalty and friendliness.', metadata={'source': 'mammal-pets-doc'}),\n",
       " Document(page_content='Dogs are great companions, known for their loyalty and friendliness.', metadata={'source': 'mammal-pets-doc'})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Async query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Cats are independent pets that often enjoy their own space.', metadata={'source': 'mammal-pets-doc'}),\n",
       " Document(page_content='Cats are independent pets that often enjoy their own space.', metadata={'source': 'mammal-pets-doc'}),\n",
       " Document(page_content='Dogs are great companions, known for their loyalty and friendliness.', metadata={'source': 'mammal-pets-doc'}),\n",
       " Document(page_content='Dogs are great companions, known for their loyalty and friendliness.', metadata={'source': 'mammal-pets-doc'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await vectorstore.asimilarity_search(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return scores:\n",
    "\n",
    "Note that providers implement different scores. In our example Chroma returns a distance metric that should vary inversely with similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Cats are independent pets that often enjoy their own space.', metadata={'source': 'mammal-pets-doc'}),\n",
       "  211890.859375),\n",
       " (Document(page_content='Cats are independent pets that often enjoy their own space.', metadata={'source': 'mammal-pets-doc'}),\n",
       "  211890.859375),\n",
       " (Document(page_content='Dogs are great companions, known for their loyalty and friendliness.', metadata={'source': 'mammal-pets-doc'}),\n",
       "  216063.953125),\n",
       " (Document(page_content='Dogs are great companions, known for their loyalty and friendliness.', metadata={'source': 'mammal-pets-doc'}),\n",
       "  216063.953125)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search_with_score(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return documents based on similarity to an embedded query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Cats are independent pets that often enjoy their own space.', metadata={'source': 'mammal-pets-doc'}),\n",
       " Document(page_content='Dogs are great companions, known for their loyalty and friendliness.', metadata={'source': 'mammal-pets-doc'}),\n",
       " Document(page_content='Rabbits are social animals that need plenty of space to hop around.', metadata={'source': 'mammal-pets-doc'}),\n",
       " Document(page_content='Parrots are intelligent birds capable of mimicking human speech.', metadata={'source': 'bird-pets-doc'})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = OllamaEmbeddings(model=\"mistral:v0.3\").embed_query(\"cat\")\n",
    "\n",
    "vectorstore.similarity_search_by_vector(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrievers\n",
    "\n",
    "LangChain `VectorStore` objects do not subclass [Runnable](https://api.python.langchain.com/en/latest/core_api_reference.html#module-langchain_core.runnables) and can not immediately be integrated into LangChain Expression Language (LCEL) [chains](https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel).\n",
    "\n",
    "LangChain [Retrievers](https://api.python.langchain.com/en/latest/core_api_reference.html#module-langchain_core.retrievers) *are* Runnables, so they implement a standard set of methods (e.g., synchronous and asynchronous `invoke` and `batch` operations) and are designed to be incorporated in LCEL chains.\n",
    "\n",
    "We can create a simple version of this ourselves, without subclassing `Retriever`. If we choose what method we wish to use to retrieve documents we can create a runnable easily. Below we will build one around the `similarity_search` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(page_content='Cats are independent pets that often enjoy their own space.', metadata={'source': 'mammal-pets-doc'})],\n",
       " [Document(page_content='Rabbits are social animals that need plenty of space to hop around.', metadata={'source': 'mammal-pets-doc'})]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "retriever = RunnableLambda(vectorstore.similarity_search).bind(k=1) #selects the best result\n",
    "\n",
    "retriever.batch([\"cat\", \"shark\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The model for some reason thinks rabbits are the closest match to shark, when it should be returning fish. Could be the model or how the data is vectorized. This is a good topic for further exploration later. Could also be the vector search method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorstores implement an `as_retriever` method that will generate a Retriever, specifically a [VectorStoreRetriever](https://api.python.langchain.com/en/latest/vectorstores/langchain_core.vectorstores.VectorStoreRetriever.html). These retrivers include specific `search_type` and `search_kwargs` attributes that identify what methods of the underlying vector store to call, and how to parameterize them. For instance we can replicate the above with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(page_content='Cats are independent pets that often enjoy their own space.', metadata={'source': 'mammal-pets-doc'})],\n",
       " [Document(page_content='Rabbits are social animals that need plenty of space to hop around.', metadata={'source': 'mammal-pets-doc'})]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 1},\n",
    ")\n",
    "\n",
    "retriever.batch([\"cat\", \"shark\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`VectorStoreRetriever` supports search types of `\"similarity\"` (default), `\"mmr\"` (maximum marginal relevance, described above), and `\"similarity_score_threshold\"`. We can use the latter to threshold documents output by the retriever by similarity score. \n",
    "\n",
    "Retrievers can easily be incorporated into more complex applications, such as RAG applications that combine a given question with retrieved context into a prompt for a LLM. Below we show a minimal example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the model\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "model = ChatOllama(model=\"mistral:v0.3\", base_url=\"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "message = \"\"\"\n",
    "Answer this question using the provided context only.\n",
    "\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])\n",
    "\n",
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " According to the document 'mammal-pets-doc', cats are considered independent pets. They tend to appreciate having their own personal space.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"Tell me about cats\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn more:\n",
    "\n",
    "Retrieval strategies can be rich and complex. For example:\n",
    "\n",
    "- We can [infer hard rules and filters](https://python.langchain.com/v0.2/docs/how_to/self_query/) from a query (e.g., \"using documents published after 2020\");\n",
    "- We can [return documents that are linked](https://python.langchain.com/v0.2/docs/how_to/parent_document_retriever/) to the retrieved context in some way (e.g., via some document taxonomy);\n",
    "- We can generate [multiple embeddings](https://python.langchain.com/v0.2/docs/how_to/multi_vector/) for each unit of context;\n",
    "- We can [ensemble results](https://python.langchain.com/v0.2/docs/how_to/ensemble_retriever/) from multiple retrievers;\n",
    "- We can assign weights to documents, e.g., to weigh [recent documents](https://python.langchain.com/v0.2/docs/how_to/time_weighted_vectorstore/) higher.\n",
    "\n",
    "The [retrievers](https://python.langchain.com/v0.2/docs/how_to/#retrievers) section of the how-to guides covers these and other built-in retrieval strategies. It is also straightforward to extend the [BaseRetriever](https://api.python.langchain.com/en/latest/retrievers/langchain_core.retrievers.BaseRetriever.html) class in order to implement custom retrievers. See the how-to guide [here](https://python.langchain.com/v0.2/docs/how_to/custom_retriever/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollamalangchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
